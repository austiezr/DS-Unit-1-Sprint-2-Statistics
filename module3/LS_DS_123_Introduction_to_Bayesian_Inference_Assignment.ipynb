{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_123_Introduction_to_Bayesian_Inference_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7OLbevlbd_Z",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science Module 123\n",
        "\n",
        "## Introduction to Bayesian Inference\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-DzzRk5bf0z",
        "colab_type": "text"
      },
      "source": [
        "## Assignment - Code it up!\n",
        "\n",
        "We used pure math to apply Bayes Theorem to drug tests. Now write Python code to reproduce the results! This is purposefully open ended - you'll have to think about how you should represent probabilities and events. You can and should look things up.\n",
        "\n",
        "Specific goals/targets:\n",
        "\n",
        "### 1) Write a function \n",
        "\n",
        "`def prob_drunk_given_positive(prob_drunk_prior, false_positive_rate):` \n",
        "\n",
        "You should only truly need these two values in order to apply Bayes Theorem. In this example, imagine that individuals are taking a breathalyzer test with an 8% false positive rate, a 100% true positive rate, and that our prior belief about drunk driving in the population is 1/1000. \n",
        " - What is the probability that a person is drunk after one positive breathalyzer test?\n",
        " - What is the probability that a person is drunk after two positive breathalyzer tests?\n",
        " - How many positive breathalyzer tests are needed in order to have a probability that's greater than 95% that a person is drunk beyond the legal limit?\n",
        "\n",
        "### 2) Explore `scipy.stats.bayes_mvs`  \n",
        "Read its documentation, and experiment with it on data you've tested in other ways earlier this week.\n",
        " - Create a visualization comparing the results of a Bayesian approach to a traditional/frequentist approach. (with a large sample size they should look close to identical, however, take this opportunity to practice visualizing condfidence intervals in general. The following are some potential ways that you could visualize confidence intervals on your graph:\n",
        "  - [Matplotlib Error Bars](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.errorbar.html)\n",
        "  - [Seaborn barplot with error bars](https://seaborn.pydata.org/generated/seaborn.barplot.html)\n",
        "  - [Vertical ines to show bounds of confidence interval](https://www.simplypsychology.org/confidence-interval.jpg)\n",
        "  - [Confidence Intervals on Box Plots](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.axes.Axes.boxplot.html)\n",
        "\n",
        "### 3) In your own words, summarize the difference between Bayesian and Frequentist statistics\n",
        "\n",
        "If you're unsure where to start, check out [this blog post of Bayes theorem with Python](https://dataconomy.com/2015/02/introduction-to-bayes-theorem-with-python/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpVhZyUnbf7o",
        "colab_type": "code",
        "outputId": "b109e510-f3ab-4e84-ec36-9d494937bdcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# TODO - code!\n",
        "\n",
        "def prob_drunk_given_positive(prob_drunk_prior=.001,\n",
        "                              false_positive_rate=.08,\n",
        "                              desired_accuracy=.95,\n",
        "                              number_of_tests=1):\n",
        "\n",
        "# Calculating probability via Bayes theorem\n",
        "    numer = (1 - false_positive_rate) * prob_drunk_prior\n",
        "    denom = numer + (false_positive_rate * (1 - prob_drunk_prior))\n",
        "    probability = (numer / denom)\n",
        "    print(f'{round(probability*100, 2)}% probability.')\n",
        "\n",
        "# Iteration based off comparison to desired accuracy\n",
        "    while probability < desired_accuracy:\n",
        "        number_of_tests += 1\n",
        "        prob_drunk_given_positive(prob_drunk_prior=probability, \n",
        "                                  number_of_tests=number_of_tests)\n",
        "        break\n",
        "    if probability >= desired_accuracy:\n",
        "        print(f'{number_of_tests} tests necessary.')\n",
        "\n",
        "\n",
        "prob_drunk_given_positive()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14% probability.\n",
            "11.69% probability.\n",
            "60.36% probability.\n",
            "94.6% probability.\n",
            "99.51% probability.\n",
            "5 tests necessary.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNY92qOtJthk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prob_drunk_given_positive_test(prob_drunk_prior=.001,\n",
        "                              false_positive_rate=.08,\n",
        "                              desired_accuracy=.95,\n",
        "                              number_of_tests=1):\n",
        "\n",
        "# Calculating probability via Bayes theorem\n",
        "    numer = (1 - false_positive_rate) * prob_drunk_prior\n",
        "    denom = numer + (false_positive_rate * (1 - prob_drunk_prior))\n",
        "    probability = (numer / denom)\n",
        "    print(f'{round(probability*100, 2)}% probability.')\n",
        "\n",
        "# Iteration based off comparison to desired accuracy\n",
        "    if probability < desired_accuracy:\n",
        "        number_of_tests += 1\n",
        "        prob_drunk_given_positive(prob_drunk_prior=probability, \n",
        "                                  number_of_tests=number_of_tests)\n",
        "    elif probability >= desired_accuracy:\n",
        "        print(f'{number_of_tests} tests necessary.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3znVl1yI8VK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b90b712-ae3b-44ac-f88d-500d9ab32513"
      },
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "\n",
        "t = timeit.Timer(setup='from __main__ import prob_drunk_given_positive_test', stmt='prob_drunk_given_positive_test')\n",
        "t2 = timeit.Timer(setup='from __main__ import prob_drunk_given_positive', stmt='prob_drunk_given_positive')\n",
        "print(np.mean(t.timeit(number=1000)) - np.mean(t2.timeit(number=1000)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.955999995421735e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBe6ryGhfu3i",
        "colab_type": "text"
      },
      "source": [
        "1.14% probability after first positive.\n",
        "\n",
        "11.69% probability after second positive.\n",
        "\n",
        "5 tests necessary for 95% probability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4RzlP_pgcb2",
        "colab_type": "code",
        "outputId": "e75f2098-afe0-47e6-b091-51f511db5570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import scipy.stats as stats\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv')\n",
        "\n",
        "bmean, bvar, bstd = stats.bayes_mvs(df['temp'])\n",
        "\n",
        "print(mean[0])\n",
        "print(var)\n",
        "print(std)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18.88916827852998\n",
            "Variance(statistic=33.848092105758305, minmax=(30.525188497228694, 37.469618781534194))\n",
            "Std_dev(statistic=5.815082284572773, minmax=(5.524960497345542, 6.121243238226544))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px6Sx84JiAHg",
        "colab_type": "code",
        "outputId": "1f3ebca3-ea32-4658-dd62-8c349eb59114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def confidence_interval(data, confidence=0.95):\n",
        "    data = np.array(data)\n",
        "    mean = np.mean(data)\n",
        "    n = len(data)\n",
        "    s = np.std(data, ddof=1)\n",
        "    stderr = s/np.sqrt(n)\n",
        "    margin_of_error = stderr * stats.t.ppf((1 + confidence) / 2.0, n - 1)\n",
        "    return (mean, mean - margin_of_error, mean + margin_of_error)\n",
        "\n",
        "confidence_interval(df['temp'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18.88916827852998, 18.38746551815681, 19.39087103890315)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbWBxFu1i-7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm = stats.norm.interval(0.05, loc=np.mean(df['temp']), scale=np.std(df['temp']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yci0Aq6omYty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CI = [mean[0], mean[1][0], mean[1][1]]\n",
        "CI_norm = [np.mean(df['temp']), norm[0], norm[1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orOlC3D9ktfZ",
        "colab_type": "code",
        "outputId": "2e0b5c87-2ad0-4c39-c676-150279450298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Frequentist\n",
        "sns.boxplot(confidence_interval(df['temp']), color='blue')\n",
        "# Bayesian\n",
        "sns.boxplot(CI, color='red')\n",
        "# stats.norm\n",
        "sns.boxplot(CI_norm, color='green')\n",
        "sns.despine(offset=10, trim=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAECCAYAAADXf53UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ9QAxQk1QHFCDVCcUAMUJ9QAxf0PmF9c+v8lMuYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8f2mRWbq1MP",
        "colab_type": "text"
      },
      "source": [
        "The key difference between Bayesian and Frequentist statistics is in how probability is used. A Bayesian statistician would begin by accounting for prior knowledge before collecting data; a Frequentist statistican would only account for probability by sampled data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWgWjp3PQ3Sq",
        "colab_type": "text"
      },
      "source": [
        "## Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgHqmYIQ9qn",
        "colab_type": "text"
      },
      "source": [
        "- [Worked example of Bayes rule calculation](https://en.wikipedia.org/wiki/Bayes'_theorem#Examples) (helpful as it fully breaks out the denominator)\n",
        "- [Source code for mvsdist in scipy](https://github.com/scipy/scipy/blob/90534919e139d2a81c24bf08341734ff41a3db12/scipy/stats/morestats.py#L139)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP7Jv1XvwtkX",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Go back and study the content from Modules 1 & 2 to make sure that you're really comfortable with them.\n",
        "- Apply a Bayesian technique to a problem you previously worked (in an assignment or project work) on from a frequentist (standard) perspective\n",
        "- Check out [PyMC3](https://docs.pymc.io/) (note this goes beyond hypothesis tests into modeling) - read the guides and work through some examples\n",
        "- Take PyMC3 further - see if you can build something with it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDi0eFr1x-v_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}